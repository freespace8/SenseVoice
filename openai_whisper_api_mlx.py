#!/usr/bin/env python3
"""
SenseVoice MLX - OpenAI Whisper Compatible API
ä½¿ç”¨ MLX åŠ é€Ÿçš„ SenseVoice æ¨¡å‹ï¼Œæä¾›ä¸ OpenAI Whisper API å…¼å®¹çš„æ¥å£
"""

import os
import time
import shutil
import logging
import tempfile
from pathlib import Path
from typing import Union, Optional, List, Dict, Any
from datetime import datetime

from fastapi import FastAPI, Form, UploadFile, File, HTTPException, status
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from pycorrector import MacBertCorrector
import numpy as np
import librosa
import soundfile as sf

# å¯¼å…¥ VoiceMLX
from voice_mlx import VoiceMLX


# é…ç½®ç®¡ç†ç±»
class Config:
    """MLX API é…ç½®ç®¡ç†"""
    
    def __init__(self):
        # æœåŠ¡å™¨é…ç½®
        self.HOST = os.getenv("SENSEVOICE_MLX_HOST", "0.0.0.0")
        self.PORT = int(os.getenv("SENSEVOICE_MLX_PORT", "6209"))
        
        # æ¨¡å‹é…ç½®
        self.MODEL_PATH = os.getenv(
            "SENSEVOICE_MLX_MODEL_PATH",
            "/Users/taylor/Documents/code/SenseVoice/model/model_mlx.safetensors"
        )
        self.MODEL_DIR = os.getenv(
            "SENSEVOICE_MODEL_DIR",
            os.path.expanduser("~/.cache/modelscope/hub/models/iic/SenseVoiceSmall")
        )
        
        # æ–‡ä»¶å¤„ç†é…ç½®
        self.TMP_DIR = os.getenv("SENSEVOICE_MLX_TMP_DIR", "./tmp_mlx")
        self.MAX_FILE_SIZE = int(os.getenv("SENSEVOICE_MAX_FILE_SIZE", str(25 * 1024 * 1024)))  # 25MB
        self.SUPPORTED_FORMATS = {'.mp3', '.mp4', '.mpeg', '.mpga', '.m4a', '.wav', '.webm', '.flac', '.ogg'}
        
        # éŸ³é¢‘å¤„ç†é…ç½®
        self.TARGET_SAMPLE_RATE = int(os.getenv("SENSEVOICE_SAMPLE_RATE", "16000"))
        
        # æ—¥å¿—é…ç½®
        self.LOG_LEVEL = os.getenv("SENSEVOICE_MLX_LOG_LEVEL", "INFO")
        
        # APIé…ç½®
        self.API_TITLE = "SenseVoice MLX - OpenAI Compatible API"
        self.API_VERSION = "1.0.0"
        self.API_DESCRIPTION = "é«˜æ€§èƒ½ MLX åŠ é€Ÿçš„è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œå…¼å®¹ OpenAI Whisper API"
        
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        os.makedirs(self.TMP_DIR, exist_ok=True)
        
        # é…ç½®æ—¥å¿—
        self._setup_logging()
    
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_file = os.path.join(self.TMP_DIR, 'api_mlx.log')
        
        # åˆ›å»ºä¸“ç”¨çš„logger
        self.logger = logging.getLogger('sensevoice_mlx')
        self.logger.setLevel(getattr(logging, self.LOG_LEVEL.upper()))
        
        # é˜²æ­¢æ—¥å¿—ä¼ æ’­åˆ°root loggerï¼Œé¿å…é‡å¤è¾“å‡º
        self.logger.propagate = False
        
        # é¿å…é‡å¤æ·»åŠ handler
        if not self.logger.handlers:
            # æ§åˆ¶å°handler
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')
            console_handler.setFormatter(console_formatter)
            
            # æ–‡ä»¶handler
            file_handler = logging.FileHandler(log_file)
            file_handler.setLevel(logging.INFO)
            file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(file_formatter)
            
            # æ·»åŠ handlers
            self.logger.addHandler(console_handler)
            self.logger.addHandler(file_handler)
    
    def print_config(self):
        """æ‰“å°å½“å‰é…ç½®"""
        print("\n" + "=" * 60)
        print("ğŸš€ SenseVoice MLX API é…ç½®")
        print("=" * 60)
        print(f"ğŸ“ æœåŠ¡åœ°å€: http://{self.HOST}:{self.PORT}")
        print(f"ğŸ’¾ æ¨¡å‹è·¯å¾„: {self.MODEL_PATH}")
        print(f"ğŸ“‚ æ¨¡å‹ç›®å½•: {self.MODEL_DIR}")
        print(f"ğŸ—‚ï¸  ä¸´æ—¶ç›®å½•: {self.TMP_DIR}")
        print(f"ğŸ“¦ æœ€å¤§æ–‡ä»¶: {self.MAX_FILE_SIZE // (1024*1024)}MB")
        print(f"ğŸ“ æ—¥å¿—çº§åˆ«: {self.LOG_LEVEL}")
        print("=" * 60 + "\n")


# åˆå§‹åŒ–é…ç½®
config = Config()
config.print_config()

# FastAPI åº”ç”¨åˆå§‹åŒ–
app = FastAPI(
    title=config.API_TITLE,
    version=config.API_VERSION,
    description=config.API_DESCRIPTION
)

# è®°å½•åº”ç”¨å¯åŠ¨æ—¶é—´
app_start_time = time.time()

# å…¨å±€æ¨¡å‹å®ä¾‹
model: Optional[VoiceMLX] = None
corrector_model: Optional[MacBertCorrector] = None

def get_corrector() -> MacBertCorrector:
    """
    è·å– MacBertCorrector æ¨¡å‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰ã€‚
    æ¨¡å‹åœ¨é¦–æ¬¡è°ƒç”¨æ—¶åˆå§‹åŒ–å¹¶ç¼“å­˜ã€‚
    """
    global corrector_model
    if corrector_model is None:
        config.logger.info("ğŸ”§ æ­£åœ¨é¦–æ¬¡åˆå§‹åŒ– MacBertCorrector æ–‡æœ¬çº é”™æ¨¡å‹...")
        config.logger.info("ğŸ“¦ æ¨¡å‹æ¥æº: shibing624/macbert4csc-base-chinese")
        start_time = time.time()
        # æ³¨æ„ï¼šMacBertCorrector é»˜è®¤ä¼šä» huggingface ä¸‹è½½æ¨¡å‹ï¼Œ
        # ä¹Ÿå¯ä»¥æŒ‡å®šæœ¬åœ°æ¨¡å‹è·¯å¾„ model_name_or_path
        corrector_model = MacBertCorrector()
        load_time = time.time() - start_time
        config.logger.info(f"âœ… MacBertCorrector æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        config.logger.info("ğŸ¯ æ–‡æœ¬çº é”™åŠŸèƒ½å·²å°±ç»ª")
    return corrector_model


def initialize_model():
    """åˆå§‹åŒ– MLX æ¨¡å‹"""
    global model
    
    try:
        print("â³ æ­£åœ¨åˆå§‹åŒ– MLX æ¨¡å‹...")
        start_time = time.time()
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–æ˜¯å¦å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        enable_punctuation = os.getenv("SENSEVOICE_ENABLE_PUNCTUATION", "true").lower() == "true"
        
        model = VoiceMLX(
            model_path=config.MODEL_PATH,
            model_dir=config.MODEL_DIR,
            verbose=True,
            enable_punctuation=enable_punctuation
        )
        
        if enable_punctuation:
            config.logger.info("âœ… æ ‡ç‚¹æ¢å¤åŠŸèƒ½å·²å¯ç”¨")
        else:
            config.logger.info("â„¹ï¸ æ ‡ç‚¹æ¢å¤åŠŸèƒ½æœªå¯ç”¨ï¼ˆè®¾ç½® SENSEVOICE_ENABLE_PUNCTUATION=true ä»¥å¯ç”¨ï¼‰")
        
        load_time = time.time() - start_time
        print(f"âœ… MLX æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        
        # é¢„çƒ­æ¨¡å‹
        print("ğŸ”¥ é¢„çƒ­æ¨¡å‹...")
        warmup_audio = np.zeros(16000, dtype=np.float32)  # 1ç§’é™éŸ³
        _ = model.transcribe(warmup_audio, language="auto")
        print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
        
        return model
        
    except Exception as e:
        config.logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ï¼š")
        print("   1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   3. Pythonç¯å¢ƒå’Œä¾èµ–æ˜¯å¦æ­£ç¡®")
        raise RuntimeError(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")


# åº”ç”¨å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹"""
    try:
        initialize_model()
        print(f"ğŸ‰ æœåŠ¡å¯åŠ¨æˆåŠŸï¼è®¿é—® http://{config.HOST}:{config.PORT}/docs æŸ¥çœ‹ API æ–‡æ¡£")
    except Exception as e:
        config.logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
        print(f"ğŸ’¥ å¯åŠ¨å¤±è´¥: {e}")


# API å“åº”æ¨¡å‹
class CorrectionResult(BaseModel):
    """æ–‡æœ¬çº é”™ç»“æœæ¨¡å‹"""
    source: str
    target: str
    errors: List[tuple] = Field(default_factory=list)

class TranscriptionResponse(BaseModel):
    """è½¬å½•å“åº”æ¨¡å‹"""
    text: str
    language: Optional[str] = None
    duration: Optional[float] = None
    words: Optional[List[Dict[str, Any]]] = None
    segments: Optional[List[Dict[str, Any]]] = None
    correction: Optional[CorrectionResult] = None # æ–°å¢å­—æ®µ


class TranslationResponse(BaseModel):
    """ç¿»è¯‘å“åº”æ¨¡å‹"""
    text: str
    language: Optional[str] = None
    duration: Optional[float] = None


# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": time.time() - app_start_time,
        "model_loaded": model is not None,
        "config": {
            "api_version": config.API_VERSION,
            "max_file_size_mb": config.MAX_FILE_SIZE // (1024 * 1024),
            "supported_formats": list(config.SUPPORTED_FORMATS)
        }
    }
    
    if model is None:
        health_status["status"] = "unhealthy"
        health_status["error"] = "Model not loaded"
        return JSONResponse(content=health_status, status_code=503)
    
    return health_status


# ç»Ÿè®¡ç«¯ç‚¹
@app.get("/stats")
async def stats():
    """API ä½¿ç”¨ç»Ÿè®¡"""
    return {
        "uptime_seconds": time.time() - app_start_time,
        "model_loaded": model is not None,
        "model_type": "MLX",
        "acceleration": "Apple Silicon",
        "config": {
            "model_path": config.MODEL_PATH,
            "sample_rate": config.TARGET_SAMPLE_RATE,
            "max_file_size_mb": config.MAX_FILE_SIZE // (1024 * 1024),
            "supported_formats": list(config.SUPPORTED_FORMATS)
        }
    }


def format_text(text: str, response_format: str = "json") -> str:
    """æ ¼å¼åŒ–è¾“å‡ºæ–‡æœ¬ï¼Œå»é™¤ç‰¹æ®Šæ ‡è®°"""
    if response_format == "json" or response_format == "verbose_json":
        # å»é™¤ç‰¹æ®Šæ ‡è®°
        import re
        # ç§»é™¤è¯­è¨€æ ‡è®°
        text = re.sub(r'<\|[a-z]+\|>', '', text)
        # ç§»é™¤æƒ…æ„Ÿæ ‡è®°
        text = re.sub(r'<\|[A-Z]+\|>', '', text)
        # ç§»é™¤äº‹ä»¶æ ‡è®°
        text = re.sub(r'<\|[A-Za-z_]+\|>', '', text)
        text = text.strip()
    
    return text


def correct_text_with_macbert(text: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ MacBert æ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œçº é”™ã€‚

    Args:
        text: å¾…çº é”™çš„åŸå§‹æ–‡æœ¬ã€‚

    Returns:
        ä¸€ä¸ªåŒ…å«çº é”™ç»“æœçš„å­—å…¸ã€‚
    """
    config.logger.info(f"ğŸ” å¼€å§‹æ–‡æœ¬çº é”™å¤„ç†...")
    config.logger.info(f"ğŸ“ åŸå§‹æ–‡æœ¬: {text}")
    config.logger.info(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¯¹äº5ä¸ªå­—ç¬¦ä»¥ä¸‹çš„çŸ­æ–‡æœ¬è·³è¿‡çº é”™
    if len(text.strip()) < 5:
        config.logger.info("ğŸ›¡ï¸ æ–‡æœ¬è¿‡çŸ­ï¼ˆ<5å­—ç¬¦ï¼‰ï¼Œè·³è¿‡çº é”™ä»¥é¿å…è¯¯åˆ¤")
        return {
            "source": text,
            "target": text,
            "errors": [],
            "inference_time": 0.0,
            "skip_reason": "æ–‡æœ¬è¿‡çŸ­ï¼ˆ<5å­—ç¬¦ï¼‰"
        }
    
    try:
        corrector = get_corrector()
        config.logger.info("âš¡ æ­£åœ¨æ‰§è¡Œ MacBert æ–‡æœ¬çº é”™...")
        start_time = time.time()
        result = corrector.correct(text)
        inference_time = time.time() - start_time
        
        corrected_text = result.get('target', text)
        errors = result.get('errors', [])
        
        # å¯¹çº é”™ç»“æœè¿›è¡Œè´¨é‡æ£€æŸ¥
        if _should_accept_correction(text, corrected_text, errors):
            config.logger.info(f"âœ… çº é”™å¤„ç†å®Œæˆ (è€—æ—¶: {inference_time:.3f}ç§’)")
            config.logger.info(f"ğŸ“ çº é”™ç»“æœ: {corrected_text}")
            config.logger.info(f"ğŸ”§ å‘ç°é”™è¯¯: {len(errors)} ä¸ª")
            
            if errors:
                config.logger.info("ğŸ“‹ é”™è¯¯è¯¦æƒ…:")
                for i, error in enumerate(errors, 1):
                    if len(error) >= 3:
                        wrong_char, correct_char, position = error[0], error[1], error[2]
                        config.logger.info(f"   {i}. ä½ç½®{position}: '{wrong_char}' â†’ '{correct_char}'")
                    else:
                        config.logger.info(f"   {i}. {error}")
            else:
                config.logger.info("âœ¨ æ–‡æœ¬æ— éœ€çº é”™ï¼Œè´¨é‡è‰¯å¥½")

            # å°† pycorrector çš„è¾“å‡ºæ ¼å¼åŒ–
            return {
                "source": result.get('source', text),
                "target": corrected_text,
                "errors": errors,
                "inference_time": inference_time
            }
        else:
            config.logger.info(f"ğŸš« çº é”™ç»“æœè´¨é‡æ£€æŸ¥æœªé€šè¿‡ï¼Œä¿æŒåŸæ–‡")
            config.logger.info(f"ğŸ“ åŸå§‹æ–‡æœ¬: {text}")
            config.logger.info(f"ğŸ“ æ¨¡å‹å»ºè®®: {corrected_text}")
            config.logger.info("âœ¨ ä¿ç•™åŸå§‹æ–‡æœ¬ä»¥é¿å…é”™è¯¯çº æ­£")
            
            return {
                "source": text,
                "target": text,
                "errors": [],
                "inference_time": inference_time,
                "rejected_suggestion": corrected_text
            }
            
    except Exception as e:
        config.logger.error(f"âŒ MacBert æ–‡æœ¬çº é”™å¤±è´¥: {e}")
        config.logger.info("ğŸ”„ å¯ç”¨å®¹é”™æ¨¡å¼ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
        # åœ¨çº é”™å¤±è´¥æ—¶ï¼Œä¼˜é›…åœ°è¿”å›åŸå§‹æ–‡æœ¬ï¼Œä¸ä¸­æ–­ä¸»æµç¨‹
        return {
            "source": text,
            "target": text,
            "errors": [],
            "error_message": str(e)
        }


def _should_accept_correction(original: str, corrected: str, errors: List) -> bool:
    """
    æ£€æŸ¥çº é”™ç»“æœæ˜¯å¦åº”è¯¥è¢«æ¥å—
    
    Args:
        original: åŸå§‹æ–‡æœ¬
        corrected: çº é”™åæ–‡æœ¬
        errors: é”™è¯¯åˆ—è¡¨
        
    Returns:
        æ˜¯å¦æ¥å—çº é”™ç»“æœ
    """
    # å¦‚æœæ²¡æœ‰ä¿®æ”¹ï¼Œç›´æ¥æ¥å—
    if original == corrected:
        return True
    
    # æ£€æŸ¥ä¿®æ”¹çš„åˆç†æ€§ - å¦‚æœä¿®æ”¹è¿‡å¤šï¼Œå¯èƒ½æ˜¯è¯¯åˆ¤
    if len(errors) > len(original) // 2:
        return False
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå…¨æ–‡æ›¿æ¢ï¼ˆå¯èƒ½æ˜¯æ¨¡å‹é”™è¯¯ï¼‰
    if len(errors) == len(original) and len(original) <= 8:
        return False
    
    return True


def process_audio_file(file_path: str, language: str = "auto", enable_punctuation: Optional[bool] = None) -> Dict[str, Any]:
    """å¤„ç†éŸ³é¢‘æ–‡ä»¶
    
    Args:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        language: è¯­è¨€è®¾ç½®
        enable_punctuation: æ˜¯å¦å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆNone æ—¶ä½¿ç”¨æ¨¡å‹é»˜è®¤è®¾ç½®ï¼‰
    """
    if model is None:
        raise HTTPException(
            status_code=503,
            detail="Model not initialized"
        )
    
    try:
        # åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(file_path, sr=config.TARGET_SAMPLE_RATE, mono=True)
        duration = len(audio) / sr
        
        # æ„å»ºè½¬å½•å‚æ•°
        transcribe_kwargs = {
            "audio": audio,
            "language": language,
            "return_tokens": False,
            "keep_special_tokens": False  # ä¸ä¿ç•™ç‰¹æ®Šæ ‡è®°
        }
        
        # å¦‚æœæŒ‡å®šäº†æ ‡ç‚¹æ¢å¤è®¾ç½®ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
        if enable_punctuation is not None:
            transcribe_kwargs["enable_punctuation"] = enable_punctuation
        
        # è½¬å½•
        result = model.transcribe(**transcribe_kwargs)
        
        # æ„å»ºå“åº”
        response = {
            "text": result["text"],
            "language": result.get("language", language),
            "duration": duration,
            "inference_time": result.get("time", 0)
        }
        
        return response
        
    except Exception as e:
        config.logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Audio processing failed: {str(e)}"
        )


# ä¸»è¦ API ç«¯ç‚¹

@app.post("/v1/audio/transcriptions")
async def transcribe_audio(
    file: UploadFile = File(...),
    model: str = Form(default="whisper-1"),
    language: Optional[str] = Form(default=None),
    prompt: Optional[str] = Form(default=None),
    response_format: str = Form(default="json"),
    temperature: float = Form(default=0.0),
    timestamp_granularities: Optional[List[str]] = Form(default=None),
    enable_punctuation: Optional[bool] = Form(default=None),
    enable_correction: bool = Form(default=True) # æ–°å¢å‚æ•°
):
    """
    è½¬å½•éŸ³é¢‘æ–‡ä»¶ï¼ˆOpenAI Whisper API å…¼å®¹ï¼‰
    
    Args:
        file: éŸ³é¢‘æ–‡ä»¶
        model: æ¨¡å‹åç§°ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼Œå®é™…ä½¿ç”¨ MLX æ¨¡å‹ï¼‰
        language: è¯­è¨€ä»£ç  (zh/en/ja/ko/yue/auto)
        prompt: æç¤ºæ–‡æœ¬ï¼ˆæš‚ä¸æ”¯æŒï¼‰
        response_format: å“åº”æ ¼å¼ (json/text/srt/verbose_json/vtt)
        temperature: æ¸©åº¦å‚æ•°ï¼ˆæš‚ä¸æ”¯æŒï¼‰
        timestamp_granularities: æ—¶é—´æˆ³ç²’åº¦ï¼ˆæš‚ä¸æ”¯æŒï¼‰
        enable_punctuation: æ˜¯å¦å¯ç”¨æ ‡ç‚¹æ¢å¤ï¼ˆNone æ—¶ä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
        enable_correction: æ˜¯å¦å¯ç”¨MacBertæ–‡æœ¬çº é”™ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    """
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    if file.size and file.size > config.MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"File size exceeds maximum limit of {config.MAX_FILE_SIZE // (1024*1024)}MB"
        )
    
    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in config.SUPPORTED_FORMATS:
        raise HTTPException(
            status_code=415,
            detail=f"Unsupported file format. Supported formats: {', '.join(config.SUPPORTED_FORMATS)}"
        )
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_file = None
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            delete=False,
            suffix=file_ext,
            dir=config.TMP_DIR
        ) as tmp:
            shutil.copyfileobj(file.file, tmp)
            temp_file = tmp.name
        
        # å¤„ç†éŸ³é¢‘
        result = process_audio_file(
            temp_file,
            language=language or "auto",
            enable_punctuation=enable_punctuation
        )
        
        # æ ¼å¼åŒ–å“åº”
        text = format_text(result["text"], response_format)
        
        if response_format == "text":
            return text
        
        elif response_format == "srt":
            # ç®€å•çš„ SRT æ ¼å¼
            srt_content = f"1\n00:00:00,000 --> 00:00:{int(result['duration']):02d},000\n{text}\n"
            return srt_content
        
        elif response_format == "vtt":
            # ç®€å•çš„ WebVTT æ ¼å¼
            vtt_content = f"WEBVTT\n\n00:00:00.000 --> 00:00:{int(result['duration']):02d}.000\n{text}\n"
            return vtt_content
        
        else:  # json æˆ– verbose_json
            response = {
                "text": text,
                "language": result.get("language", "auto"),
                "duration": result.get("duration", 0)
            }

            # å¦‚æœå¯ç”¨äº†æ–‡æœ¬çº é”™ï¼Œåˆ™æ‰§è¡Œå¹¶æ·»åŠ åˆ°å“åº”ä¸­
            if enable_correction:
                config.logger.info("ğŸ¯ å¯ç”¨æ–‡æœ¬çº é”™åŠŸèƒ½")
                correction_result = correct_text_with_macbert(text)
                response["correction"] = correction_result
                config.logger.info("ğŸ“Š çº é”™ç»“æœå·²æ·»åŠ åˆ°å“åº”ä¸­")
                # å¯é€‰ï¼šç”¨çº é”™åçš„æ–‡æœ¬è¦†ç›–åŸå§‹æ–‡æœ¬
                # response["text"] = correction_result["target"]
            else:
                config.logger.info("âš ï¸  æ–‡æœ¬çº é”™åŠŸèƒ½å·²ç¦ç”¨")
            
            if response_format == "verbose_json":
                # æ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯
                response["task"] = "transcribe"
                response["model"] = "sensevoice-mlx"
                response["inference_time"] = result.get("inference_time", 0)
                
                # åˆ›å»ºç®€å•çš„æ®µè½ä¿¡æ¯
                response["segments"] = [{
                    "id": 0,
                    "start": 0.0,
                    "end": result.get("duration", 0),
                    "text": text,
                    "temperature": temperature
                }]
            
            return response
            
    except HTTPException:
        raise
    except Exception as e:
        config.logger.error(f"è½¬å½•å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Transcription failed: {str(e)}"
        )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file and os.path.exists(temp_file):
            try:
                os.remove(temp_file)
            except:
                pass


@app.post("/v1/audio/translations")
async def translate_audio(
    file: UploadFile = File(...),
    model: str = Form(default="whisper-1"),
    prompt: Optional[str] = Form(default=None),
    response_format: str = Form(default="json"),
    temperature: float = Form(default=0.0)
):
    """
    ç¿»è¯‘éŸ³é¢‘æ–‡ä»¶åˆ°è‹±æ–‡ï¼ˆOpenAI Whisper API å…¼å®¹ï¼‰
    
    æ³¨æ„ï¼šSenseVoice ä¸ç›´æ¥æ”¯æŒç¿»è¯‘ï¼Œæ­¤ç«¯ç‚¹è¿”å›è½¬å½•ç»“æœ
    """
    
    # ä½¿ç”¨è½¬å½•åŠŸèƒ½
    result = await transcribe_audio(
        file=file,
        model=model,
        language="auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
        prompt=prompt,
        response_format=response_format,
        temperature=temperature
    )
    
    # å¦‚æœæ˜¯ JSON æ ¼å¼ï¼Œæ·»åŠ ç¿»è¯‘è¯´æ˜
    if isinstance(result, dict):
        result["note"] = "Translation not supported, returning transcription"
    
    return result


# æ‰¹é‡å¤„ç†ç«¯ç‚¹ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰
@app.post("/v1/audio/batch")
async def batch_transcribe(
    files: List[UploadFile] = File(...),
    language: str = Form(default="auto"),
    response_format: str = Form(default="json")
):
    """
    æ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰
    
    Args:
        files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
        language: è¯­è¨€ä»£ç 
        response_format: å“åº”æ ¼å¼
    """
    
    results = []
    
    for file in files:
        try:
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            result = await transcribe_audio(
                file=file,
                language=language,
                response_format=response_format
            )
            
            results.append({
                "filename": file.filename,
                "status": "success",
                "result": result
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "status": "error",
                "error": str(e)
            })
    
    return {"results": results}


# æ€§èƒ½åŸºå‡†æµ‹è¯•ç«¯ç‚¹ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰
@app.post("/v1/benchmark")
async def benchmark(
    file: UploadFile = File(...),
    iterations: int = Form(default=5)
):
    """
    æ€§èƒ½åŸºå‡†æµ‹è¯•
    
    Args:
        file: æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
        iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
    """
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_file = None
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        file_ext = Path(file.filename).suffix.lower()
        with tempfile.NamedTemporaryFile(
            delete=False,
            suffix=file_ext,
            dir=config.TMP_DIR
        ) as tmp:
            shutil.copyfileobj(file.file, tmp)
            temp_file = tmp.name
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        if model is None:
            raise HTTPException(
                status_code=503,
                detail="Model not initialized"
            )
        
        benchmark_result = model.benchmark(temp_file, iterations=iterations)
        
        return {
            "filename": file.filename,
            "iterations": iterations,
            "mean_time": benchmark_result["mean_time"],
            "std_time": benchmark_result["std_time"],
            "min_time": benchmark_result["min_time"],
            "max_time": benchmark_result["max_time"],
            "throughput": 1.0 / benchmark_result["mean_time"] if benchmark_result["mean_time"] > 0 else 0
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Benchmark failed: {str(e)}"
        )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file and os.path.exists(temp_file):
            try:
                os.remove(temp_file)
            except:
                pass


# æ ¹è·¯å¾„
@app.get("/")
async def root():
    """API æ ¹è·¯å¾„"""
    return {
        "name": config.API_TITLE,
        "version": config.API_VERSION,
        "description": config.API_DESCRIPTION,
        "endpoints": {
            "transcribe": "/v1/audio/transcriptions",
            "translate": "/v1/audio/translations",
            "batch": "/v1/audio/batch",
            "benchmark": "/v1/benchmark",
            "health": "/health",
            "stats": "/stats",
            "docs": "/docs"
        },
        "model": "SenseVoice MLX",
        "acceleration": "Apple Silicon Optimized"
    }


if __name__ == "__main__":
    import uvicorn
    
    # è¿è¡ŒæœåŠ¡å™¨
    uvicorn.run(
        app,
        host=config.HOST,
        port=config.PORT,
        reload=False,  # ç”Ÿäº§ç¯å¢ƒè®¾ä¸º False
        log_level=config.LOG_LEVEL.lower()
    )