#!/usr/bin/env python3
"""
SenseVoice æ¨¡å‹å¯¹æ¯”å·¥å…· - PyTorch vs MLX
æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„æ¨ç†é€Ÿåº¦å’Œè¾“å‡ºç»“æœ
"""

import os
import sys
import time
import torch
from pathlib import Path
from rich.console import Console
from rich.table import Table

# è®¾ç½® CUDA è®¾å¤‡ä¸º CPU (Mac ç¯å¢ƒ)
os.environ['CUDA_VISIBLE_DEVICES'] = ''
torch.set_default_tensor_type('torch.FloatTensor')

# å¯¼å…¥æ¨¡å‹
from model import SenseVoiceSmall
from voice_mlx import VoiceMLX  # ä½¿ç”¨æ–°çš„å°è£…ç±»

# å¯¼å…¥ FunASR
from funasr import AutoModel


def load_pytorch_model(model_dir="/Users/taylor/.cache/modelscope/hub/models/iic/SenseVoiceSmall"):
    """åŠ è½½ PyTorch æ¨¡å‹"""
    print("\nğŸ“¦ åŠ è½½ PyTorch æ¨¡å‹...")
    start_time = time.time()
    
    # ä½¿ç”¨ from_pretrained æ–¹æ³•åŠ è½½
    try:
        # å¼ºåˆ¶ä½¿ç”¨ CPU
        model, kwargs = SenseVoiceSmall.from_pretrained(
            model=model_dir, 
            device="cpu",
            disable_update=True,
            disable_log=True
        )
        model.eval()
        load_time = time.time() - start_time
        print(f"   âœ… PyTorch æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        return model, kwargs
    except Exception as e:
        print(f"   âŒ PyTorch æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None


def load_mlx_model(model_path="/Users/taylor/Documents/code/SenseVoice/model/model_mlx.safetensors"):
    """åŠ è½½ MLX æ¨¡å‹ (ä½¿ç”¨ VoiceMLX å°è£…)"""
    print("\nğŸ“¦ åŠ è½½ MLX æ¨¡å‹...")
    start_time = time.time()
    
    try:
        # ä½¿ç”¨ VoiceMLX å°è£…ç±»
        model = VoiceMLX(
            model_path=model_path,
            verbose=False  # é¿å…é‡å¤è¾“å‡º
        )
        
        load_time = time.time() - start_time
        print(f"   âœ… MLX æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        return model
    except Exception as e:
        print(f"   âŒ MLX æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None




def inference_pytorch(model, kwargs, audio_path, language="auto"):
    """ä½¿ç”¨ PyTorch æ¨¡å‹è¿›è¡Œæ¨ç†"""
    print(f"\nğŸ”¥ PyTorch æ¨ç†: {audio_path}")
    
    try:
        # ä½¿ç”¨æ¨¡å‹çš„ inference æ–¹æ³•
        start_time = time.time()
        
        res = model.inference(
            data_in=audio_path,
            language=language,
            use_itn=False,
            ban_emo_unk=False,
            **kwargs
        )
        
        inference_time = time.time() - start_time
        
        if res and len(res) > 0:
            text = res[0][0]['text'] if isinstance(res[0], list) else res[0]['text']
            print(f"   â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
            print(f"   ğŸ“ è¯†åˆ«ç»“æœ: {text}")
            return text, inference_time
        else:
            print(f"   âŒ æ— è¯†åˆ«ç»“æœ")
            return "[æ— è¯†åˆ«ç»“æœ]", inference_time
            
    except Exception as e:
        print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return f"[é”™è¯¯: {str(e)}]", 0


def inference_mlx(model, audio_path, language="auto", keep_special_tokens=False):
    """ä½¿ç”¨ MLX æ¨¡å‹è¿›è¡Œæ¨ç† (ä½¿ç”¨ VoiceMLX å°è£…)
    
    Args:
        model: VoiceMLX å®ä¾‹
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        language: è¯­è¨€è®¾ç½®
        keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚è¯­è¨€ã€æƒ…æ„Ÿæ ‡è®°ï¼‰
    """
    print(f"\nâš¡ MLX æ¨ç†: {audio_path}")
    
    try:
        # ä½¿ç”¨ VoiceMLX çš„ transcribe æ–¹æ³•
        start_time = time.time()
        result = model.transcribe(
            audio_path,
            language=language,
            return_tokens=True,
            keep_special_tokens=keep_special_tokens
        )
        inference_time = time.time() - start_time
        
        text = result['text']
        tokens = result.get('tokens', [])
        
        print(f"   â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’")
        print(f"   ğŸ“ è¯†åˆ«ç»“æœ: {text}")
        return text, inference_time, tokens
        
    except Exception as e:
        print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
        return f"[é”™è¯¯: {str(e)}]", 0, []


def calculate_similarity(text1, text2):
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
    try:
        from difflib import SequenceMatcher
        
        # æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤ç‰¹æ®Šæ ‡è®°
        def clean_text(text):
            # å»é™¤ç‰¹æ®Šæ ‡è®°
            import re
            text = re.sub(r'<\|[^|]+\|>', '', text)
            text = text.strip()
            return text
        
        clean1 = clean_text(text1)
        clean2 = clean_text(text2)
        
        # å¦‚æœå…¶ä¸­ä¸€ä¸ªæ˜¯ token åˆ—è¡¨ï¼Œè¿”å› 0
        if "[Tokens:" in text2 or "[é”™è¯¯:" in text1 or "[é”™è¯¯:" in text2:
            return 0.0
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, clean1, clean2).ratio()
        return similarity * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    except:
        return 0.0


def compare_models(audio_files):
    """å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½"""
    print("\n" + "=" * 80)
    print("ğŸ”¬ SenseVoice æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    # åŠ è½½æ¨¡å‹
    pytorch_model, pytorch_kwargs = load_pytorch_model()
    mlx_model = load_mlx_model()
    
    if not pytorch_model or not mlx_model:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”")
        return
    
    
    # å¯¹æ¯”ç»“æœ
    results = []
    
    for audio_file in audio_files:
        print("\n" + "-" * 80)
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {os.path.basename(audio_file)}")
        
        # ä»æ–‡ä»¶åæ¨æ–­è¯­è¨€
        filename = os.path.basename(audio_file)
        if filename.startswith('zh'):
            language = 'zh'
        elif filename.startswith('en'):
            language = 'en'
        elif filename.startswith('ja'):
            language = 'ja'
        elif filename.startswith('ko'):
            language = 'ko'
        elif filename.startswith('yue'):
            language = 'yue'
        else:
            language = 'auto'
        
        print(f"   ğŸŒ è¯­è¨€: {language}")
        
        # PyTorch æ¨ç†
        pytorch_text, pytorch_time = inference_pytorch(
            pytorch_model, pytorch_kwargs, audio_file, language
        )
        
        # MLX æ¨ç†ï¼ˆä¿ç•™ç‰¹æ®Šæ ‡è®°ä»¥åŒ¹é… PyTorch è¾“å‡ºæ ¼å¼ï¼‰
        mlx_text, mlx_time, mlx_tokens = inference_mlx(
            mlx_model, audio_file, language, keep_special_tokens=True
        )
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        if pytorch_time > 0 and mlx_time > 0:
            speedup = pytorch_time / mlx_time
            print(f"\n   âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
        else:
            speedup = 0
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = calculate_similarity(pytorch_text, mlx_text)
        print(f"   ğŸ“Š æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity:.1f}%")
        
        results.append({
            'file': os.path.basename(audio_file),
            'language': language,
            'pytorch_text': pytorch_text,
            'pytorch_time': pytorch_time,
            'mlx_text': mlx_text,
            'mlx_time': mlx_time,
            'speedup': speedup,
            'similarity': similarity,
            'mlx_tokens': mlx_tokens
        })
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š å¯¹æ¯”ç»“æœæ±‡æ€»")
    print("=" * 80)
    
    total_pytorch_time = sum(r['pytorch_time'] for r in results)
    total_mlx_time = sum(r['mlx_time'] for r in results)
    avg_similarity = sum(r['similarity'] for r in results) / len(results) if results else 0
    avg_speedup = total_pytorch_time/total_mlx_time if total_mlx_time > 0 else 0
    
    # åˆ›å»º Rich è¡¨æ ¼
    console = Console()
    table = Table(title="", show_header=True, header_style="bold cyan")
    
    # æ·»åŠ åˆ—
    table.add_column("æ–‡ä»¶", style="yellow", no_wrap=True, width=12)
    table.add_column("PyTorch(s)", justify="right", style="red", width=12)
    table.add_column("MLX(s)", justify="right", style="green", width=10)
    table.add_column("åŠ é€Ÿæ¯”", justify="right", style="magenta", width=10)
    table.add_column("ç›¸ä¼¼åº¦", justify="right", style="blue", width=10)
    
    # æ·»åŠ æ•°æ®è¡Œ
    for r in results:
        table.add_row(
            r['file'],
            f"{r['pytorch_time']:.3f}",
            f"{r['mlx_time']:.3f}",
            f"{r['speedup']:.2f}x",
            f"{r['similarity']:.1f}%"
        )
    
    # æ·»åŠ åˆ†éš”çº¿
    table.add_section()
    
    # æ·»åŠ æ±‡æ€»è¡Œ
    table.add_row(
        "æ€»è®¡/å¹³å‡",
        f"{total_pytorch_time:.3f}",
        f"{total_mlx_time:.3f}",
        f"{avg_speedup:.2f}x",
        f"{avg_similarity:.1f}%",
        style="bold"
    )
    
    # æ‰“å°è¡¨æ ¼
    print()
    console.print(table)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_file = "model_comparison_results.txt"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("SenseVoice æ¨¡å‹å¯¹æ¯”ç»“æœ\n")
        f.write("=" * 80 + "\n\n")
        
        for r in results:
            f.write(f"æ–‡ä»¶: {r['file']}\n")
            f.write(f"è¯­è¨€: {r['language']}\n")
            f.write(f"PyTorch ç»“æœ: {r['pytorch_text']}\n")
            f.write(f"PyTorch æ—¶é—´: {r['pytorch_time']:.3f}ç§’\n")
            f.write(f"MLX ç»“æœ: {r['mlx_text']}\n")
            f.write(f"MLX æ—¶é—´: {r['mlx_time']:.3f}ç§’\n")
            f.write(f"åŠ é€Ÿæ¯”: {r['speedup']:.2f}x\n")
            f.write(f"æ–‡æœ¬ç›¸ä¼¼åº¦: {r['similarity']:.1f}%\n")
            if 'mlx_tokens' in r and r['mlx_tokens']:
                f.write(f"MLX Tokens (å‰20ä¸ª): {r['mlx_tokens'][:20]}\n")
            f.write("-" * 40 + "\n\n")
        
        f.write(f"\næ€»è®¡:\n")
        f.write(f"PyTorch æ€»æ—¶é—´: {total_pytorch_time:.3f}ç§’\n")
        f.write(f"MLX æ€»æ—¶é—´: {total_mlx_time:.3f}ç§’\n")
        f.write(f"å¹³å‡åŠ é€Ÿæ¯”: {total_pytorch_time/total_mlx_time if total_mlx_time > 0 else 0:.2f}x\n")
        f.write(f"å¹³å‡æ–‡æœ¬ç›¸ä¼¼åº¦: {avg_similarity:.1f}%\n")
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    # ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶
    examples_dir = "/Users/taylor/Documents/code/SenseVoice/examples"
    
    if not os.path.exists(examples_dir):
        print(f"âŒ ç¤ºä¾‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {examples_dir}")
        return
    
    # è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    audio_files = sorted([
        os.path.join(examples_dir, f) 
        for f in os.listdir(examples_dir) 
        if f.endswith('.mp3')
    ])
    
    if not audio_files:
        print(f"âŒ åœ¨ {examples_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    
    # è¿›è¡Œå¯¹æ¯”
    compare_models(audio_files)


if __name__ == "__main__":
    main()