#!/usr/bin/env python3
"""
SenseVoice ç»Ÿä¸€æ¨ç†å™¨
å®ç°MLXä¼˜å…ˆï¼Œè‡ªåŠ¨å›é€€åˆ°PyTorchçš„æ™ºèƒ½æ¨ç†ç³»ç»Ÿ
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import Optional, Tuple, Union
import numpy as np

# å°è¯•å¯¼å…¥MLX
try:
    import mlx.core as mx
    from safetensors import safe_open
    MLX_AVAILABLE = True
except ImportError:
    MLX_AVAILABLE = False
    print("âš ï¸ MLX æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ PyTorch åç«¯")

# å°è¯•å¯¼å…¥PyTorch
try:
    from funasr import AutoModel
    import torch
    PYTORCH_AVAILABLE = True
except ImportError:
    PYTORCH_AVAILABLE = False
    if not MLX_AVAILABLE:
        print("âŒ MLX å’Œ PyTorch éƒ½æœªå®‰è£…ï¼Œè¯·è‡³å°‘å®‰è£…ä¸€ä¸ªæ¨ç†åç«¯")

# éŸ³é¢‘å¤„ç†åº“
try:
    import soundfile as sf
    import librosa
except ImportError:
    print("âš ï¸ éŸ³é¢‘å¤„ç†åº“æœªå®Œæ•´å®‰è£…")

from .config import config


class UnifiedTranscriber:
    """
    ç»Ÿä¸€è½¬å½•å™¨ - MLXä¼˜å…ˆï¼Œè‡ªåŠ¨å›é€€åˆ°PyTorch
    æä¾›ç»Ÿä¸€çš„æ¥å£ï¼Œå±è”½åº•å±‚å®ç°ç»†èŠ‚
    """
    
    def __init__(self, force_backend: Optional[str] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è½¬å½•å™¨
        
        Args:
            force_backend: å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šåç«¯ ('mlx', 'pytorch', Noneä¸ºè‡ªåŠ¨)
        """
        self.backend = None
        self.model = None
        self.frontend = None
        self.id2token = None
        
        # å†³å®šä½¿ç”¨å“ªä¸ªåç«¯
        if force_backend == 'mlx' and MLX_AVAILABLE:
            self._init_mlx()
        elif force_backend == 'pytorch' and PYTORCH_AVAILABLE:
            self._init_pytorch()
        else:
            # è‡ªåŠ¨é€‰æ‹©ï¼šMLXä¼˜å…ˆ
            if MLX_AVAILABLE and config.mlx_weights_path and config.mlx_weights_path.exists():
                print("âœ… æ£€æµ‹åˆ° MLX å¯ç”¨ï¼Œä½¿ç”¨ MLX åç«¯è¿›è¡ŒåŠ é€Ÿæ¨ç†")
                self._init_mlx()
            elif PYTORCH_AVAILABLE:
                print("âš ï¸ MLX ä¸å¯ç”¨æˆ–æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå›é€€åˆ° PyTorch åç«¯")
                self._init_pytorch()
            else:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨ç†åç«¯")
    
    def _init_mlx(self):
        """åˆå§‹åŒ–MLXåç«¯"""
        try:
            print("ğŸ åˆå§‹åŒ– MLX æ¨¡å‹...")
            
            # å»¶è¿Ÿå¯¼å…¥MLXç‰¹å®šæ¨¡å—
            from .model_mlx import SenseVoiceMLX
            from .frontend_unified import create_unified_frontend
            
            # åˆå§‹åŒ–æ¨¡å‹
            self.model = SenseVoiceMLX(input_size=560)
            
            # åŠ è½½æƒé‡
            self._load_mlx_weights()
            
            # åˆ›å»ºå‰ç«¯å¤„ç†å™¨
            self.frontend = create_unified_frontend(
                cmvn_file=str(config.cmvn_file) if config.cmvn_file else None,
                dither=config.dither
            )
            
            # åŠ è½½è¯æ±‡è¡¨
            self._load_vocab()
            
            self.backend = 'mlx'
            print("âœ… MLX æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ MLX åˆå§‹åŒ–å¤±è´¥: {e}")
            if PYTORCH_AVAILABLE:
                print("âš ï¸ å›é€€åˆ° PyTorch åç«¯")
                self._init_pytorch()
    
    def _init_pytorch(self):
        """åˆå§‹åŒ–PyTorchåç«¯"""
        if not PYTORCH_AVAILABLE:
            print("âŒ PyTorch åç«¯ä¸å¯ç”¨")
            return
        
        try:
            print("ğŸ”¥ åˆå§‹åŒ– PyTorch æ¨¡å‹...")
            
            # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹è·¯å¾„
            model_path = str(config.model_dir) if config.model_dir.exists() else config.model_name
            
            self.model = AutoModel(
                model=model_path,
                trust_remote_code=True,
                remote_code=str(config.model_dir / "model.py") if (config.model_dir / "model.py").exists() else None,
                vad_model=None,
                device="cuda" if torch.cuda.is_available() and config.device != "cpu" else "cpu",
            )
            
            self.backend = 'pytorch'
            print("âœ… PyTorch æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ PyTorch åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _load_mlx_weights(self):
        """åŠ è½½MLXæ¨¡å‹æƒé‡"""
        if not config.mlx_weights_path or not config.mlx_weights_path.exists():
            raise FileNotFoundError(f"MLXæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {config.mlx_weights_path}")
        
        weights = {}
        with safe_open(str(config.mlx_weights_path), framework="pt", device="cpu") as f:
            for key in f.keys():
                tensor = f.get_tensor(key)
                weights[key] = mx.array(tensor.numpy())
        
        # çµæ´»åŠ è½½æƒé‡
        for key, value in weights.items():
            try:
                parts = key.split('.')
                current = self.model
                for part in parts[:-1]:
                    if hasattr(current, part):
                        current = getattr(current, part)
                    else:
                        break
                else:
                    if hasattr(current, parts[-1]):
                        setattr(current, parts[-1], value)
            except:
                pass
    
    def _load_vocab(self):
        """åŠ è½½è¯æ±‡è¡¨"""
        if config.vocab_path and config.vocab_path.exists():
            with open(config.vocab_path, 'r', encoding='utf-8') as f:
                vocab_list = json.load(f)
            self.id2token = {i: token for i, token in enumerate(vocab_list)}
        else:
            self.id2token = None
    
    def transcribe(self, audio_input: Union[str, Path, np.ndarray], language: str = "auto") -> dict:
        """
        ç»Ÿä¸€çš„è½¬å½•æ¥å£
        
        Args:
            audio_input: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
            language: è¯­è¨€ä»£ç  (auto, zh, en, jaç­‰)
        
        Returns:
            dict: åŒ…å«è½¬å½•ç»“æœå’Œå…ƒä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        
        if self.backend == 'mlx':
            result = self._transcribe_mlx(audio_input, language)
        elif self.backend == 'pytorch':
            result = self._transcribe_pytorch(audio_input, language)
        else:
            return {'text': '', 'error': 'æ²¡æœ‰åˆå§‹åŒ–çš„æ¨ç†åç«¯'}
        
        # æ·»åŠ å…¬å…±å…ƒä¿¡æ¯
        result['backend'] = self.backend
        result['total_time'] = time.time() - start_time
        
        if result.get('duration', 0) > 0:
            result['rtf'] = result['duration'] / result['total_time']
        
        return result
    
    def _transcribe_mlx(self, audio_input: Union[str, Path, np.ndarray], language: str) -> dict:
        """MLXåç«¯è½¬å½•"""
        # å¤„ç†éŸ³é¢‘
        if isinstance(audio_input, (str, Path)):
            audio_path = str(audio_input)
            if audio_path.endswith('.mp3'):
                audio, sr = librosa.load(audio_path, sr=None, mono=True)
            else:
                audio, sr = sf.read(audio_path)
                if len(audio.shape) > 1:
                    audio = audio.mean(axis=1)
        else:
            audio = audio_input
            sr = config.sample_rate
        
        # é‡é‡‡æ ·åˆ°16kHz
        if sr != config.sample_rate:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=config.sample_rate)
        
        audio = audio.astype(np.float32)
        duration = len(audio) / config.sample_rate
        
        # ç‰¹å¾æå–
        features = self.frontend(audio, output_format="mlx")
        
        # å‡†å¤‡è¾“å…¥
        batch_size, seq_len, _ = features.shape
        x_lens = mx.array([seq_len] * batch_size, dtype=mx.int32)
        
        # æ¨ç†
        if language == "auto":
            # ä»éŸ³é¢‘ä¸­è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            language = "zh"  # é»˜è®¤ä¸­æ–‡
        
        encoder_out, encoder_out_lens = self.model.encode(features, x_lens, language=language)
        ctc_out = self.model.ctc.get_logits(encoder_out)
        
        # CTCè§£ç 
        predictions = mx.argmax(ctc_out, axis=-1)
        
        # å»é™¤é‡å¤å’Œç©ºç™½
        decoded = []
        prev_token = -1
        for token in predictions[0].tolist():
            if token != 0 and token != prev_token:
                decoded.append(token)
            prev_token = token
        
        # è§£ç ä¸ºæ–‡æœ¬
        text = self._decode_tokens(decoded)
        
        return {
            'text': text,
            'duration': duration,
            'language': language,
            'tokens': decoded
        }
    
    def _transcribe_pytorch(self, audio_input: Union[str, Path, np.ndarray], language: str) -> dict:
        """PyTorchåç«¯è½¬å½•"""
        # å¦‚æœæ˜¯numpyæ•°ç»„ï¼Œå…ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_file = None
        if isinstance(audio_input, np.ndarray):
            import tempfile
            temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            sf.write(temp_file.name, audio_input, config.sample_rate)
            audio_path = temp_file.name
        else:
            audio_path = str(audio_input)
        
        try:
            # ä½¿ç”¨FunASRæ¨ç†
            res = self.model.generate(
                input=audio_path,
                cache={},
                language=language if language != "auto" else "auto",
                use_itn=False,
            )
            
            # è·å–éŸ³é¢‘æ—¶é•¿
            if audio_path.endswith('.mp3'):
                audio, sr = librosa.load(audio_path, sr=None)
            else:
                audio, sr = sf.read(audio_path)
            duration = len(audio) / sr
            
            # æå–ç»“æœ
            if res and len(res) > 0:
                text = res[0].get("text", "")
                return {
                    'text': text,
                    'duration': duration,
                    'language': res[0].get("language", language)
                }
            
            return {
                'text': "",
                'duration': duration,
                'language': language
            }
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file:
                os.unlink(temp_file.name)
    
    def _decode_tokens(self, token_ids: list) -> str:
        """è§£ç token IDä¸ºæ–‡æœ¬"""
        if self.id2token is None:
            return ' '.join([f"[{t}]" for t in token_ids])
        
        text_parts = []
        for token_id in token_ids:
            token_id = int(token_id)
            
            if token_id == 0:  # blank
                continue
            elif token_id == 1:  # <sos>
                text_parts.append("<S>")
            elif token_id == 2:  # <eos>
                text_parts.append("<E>")
            elif token_id in self.id2token:
                token = self.id2token[token_id]
                text_parts.append(token)
            else:
                text_parts.append(f"[{token_id}]")
        
        text = ''.join(text_parts)
        text = text.replace("â–", " ")
        text = text.strip()
        
        return text
    
    def get_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'backend': self.backend,
            'mlx_available': MLX_AVAILABLE,
            'pytorch_available': PYTORCH_AVAILABLE,
            'config': str(config)
        }


def create_transcriber(**kwargs) -> UnifiedTranscriber:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºç»Ÿä¸€è½¬å½•å™¨å®ä¾‹"""
    return UnifiedTranscriber(**kwargs)