"""
Unified Frontend for both PyTorch and MLX versions
Ensures 100% identical feature extraction
"""

import numpy as np
import kaldi_native_fbank as knf
from typing import Optional, Tuple, Literal


class UnifiedFrontend:
    """
    ç»Ÿä¸€çš„å‰ç«¯å¤„ç†å™¨ï¼Œå¯åŒæ—¶ç”¨äº PyTorch å’Œ MLX
    ä¿è¯ç‰¹å¾æå–100%ä¸€è‡´
    """
    
    def __init__(
        self,
        fs: int = 16000,
        window: str = "hamming",
        n_mels: int = 80,
        frame_length: int = 25,
        frame_shift: int = 10,
        lfr_m: int = 7,
        lfr_n: int = 6,
        dither: float = 1.0,
        cmvn_file: Optional[str] = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–ç»Ÿä¸€çš„å‰ç«¯å¤„ç†å™¨
        
        Args:
            fs: é‡‡æ ·ç‡ (Hz)
            window: çª—å‡½æ•°ç±»å‹
            n_mels: Melé¢‘å¸¦æ•°é‡
            frame_length: å¸§é•¿ (æ¯«ç§’)
            frame_shift: å¸§ç§» (æ¯«ç§’)
            lfr_m: LFRå †å å¸§æ•°
            lfr_n: LFRå¸§ç§»
            dither: æŠ–åŠ¨å› å­
            cmvn_file: CMVNç»Ÿè®¡æ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»º Kaldi fbank é€‰é¡¹
        opts = knf.FbankOptions()
        opts.frame_opts.samp_freq = fs
        opts.frame_opts.dither = dither
        opts.frame_opts.window_type = window
        opts.frame_opts.frame_shift_ms = float(frame_shift)
        opts.frame_opts.frame_length_ms = float(frame_length)
        opts.mel_opts.num_bins = n_mels
        opts.energy_floor = 0
        opts.frame_opts.snip_edges = True
        opts.mel_opts.debug_mel = False
        self.opts = opts
        
        self.lfr_m = lfr_m
        self.lfr_n = lfr_n
        self.cmvn_file = cmvn_file
        
        # åŠ è½½ CMVN
        self.cmvn = None
        if self.cmvn_file:
            self.cmvn = self._load_cmvn(cmvn_file)
    
    def _load_cmvn(self, cmvn_file: str) -> np.ndarray:
        """åŠ è½½CMVNç»Ÿè®¡æ–‡ä»¶"""
        with open(cmvn_file, "r", encoding="utf-8") as f:
            lines = f.readlines()
        
        means_list = []
        vars_list = []
        for i in range(len(lines)):
            line_item = lines[i].split()
            if line_item[0] == "<AddShift>":
                line_item = lines[i + 1].split()
                if line_item[0] == "<LearnRateCoef>":
                    add_shift_line = line_item[3 : (len(line_item) - 1)]
                    means_list = list(add_shift_line)
                    continue
            elif line_item[0] == "<Rescale>":
                line_item = lines[i + 1].split()
                if line_item[0] == "<LearnRateCoef>":
                    rescale_line = line_item[3 : (len(line_item) - 1)]
                    vars_list = list(rescale_line)
                    continue
        
        means = np.array(means_list).astype(np.float64)
        vars = np.array(vars_list).astype(np.float64)
        cmvn = np.array([means, vars])
        return cmvn
    
    def extract_fbank(self, waveform: np.ndarray) -> np.ndarray:
        """
        æå– Fbank ç‰¹å¾
        
        Args:
            waveform: éŸ³é¢‘ä¿¡å· (numpy array)
            
        Returns:
            Fbank ç‰¹å¾ [frames, n_mels]
        """
        # ç¼©æ”¾æ³¢å½¢
        waveform = waveform * (1 << 15)
        
        # åˆ›å»º OnlineFbank å®ä¾‹
        fbank_fn = knf.OnlineFbank(self.opts)
        
        # æ¥å—æ³¢å½¢
        fbank_fn.accept_waveform(self.opts.frame_opts.samp_freq, waveform.tolist())
        
        # è·å–å¸§æ•°
        frames = fbank_fn.num_frames_ready
        
        # æå–ç‰¹å¾
        mat = np.empty([frames, self.opts.mel_opts.num_bins])
        for i in range(frames):
            mat[i, :] = fbank_fn.get_frame(i)
        
        # è½¬æ¢ä¸º float32
        feat = mat.astype(np.float32)
        return feat
    
    def apply_lfr(self, inputs: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨ LFR (Low Frame Rate) å¤„ç†
        
        Args:
            inputs: è¾“å…¥ç‰¹å¾ [frames, feature_dim]
            
        Returns:
            LFR å¤„ç†åçš„ç‰¹å¾ [lfr_frames, feature_dim * lfr_m]
        """
        if self.lfr_m == 1 and self.lfr_n == 1:
            return inputs
        
        LFR_inputs = []
        
        T = inputs.shape[0]
        T_lfr = int(np.ceil(T / self.lfr_n))
        left_padding = np.tile(inputs[0], ((self.lfr_m - 1) // 2, 1))
        inputs = np.vstack((left_padding, inputs))
        T = T + (self.lfr_m - 1) // 2
        
        for i in range(T_lfr):
            if self.lfr_m <= T - i * self.lfr_n:
                LFR_inputs.append((inputs[i * self.lfr_n : i * self.lfr_n + self.lfr_m]).reshape(1, -1))
            else:
                # å¤„ç†æœ€åä¸€ä¸ª LFR å¸§
                num_padding = self.lfr_m - (T - i * self.lfr_n)
                frame = inputs[i * self.lfr_n :].reshape(-1)
                for _ in range(num_padding):
                    frame = np.hstack((frame, inputs[-1]))
                LFR_inputs.append(frame)
        
        LFR_outputs = np.vstack(LFR_inputs).astype(np.float32)
        return LFR_outputs
    
    def apply_cmvn(self, inputs: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨ CMVN å½’ä¸€åŒ–
        
        Args:
            inputs: è¾“å…¥ç‰¹å¾
            
        Returns:
            å½’ä¸€åŒ–åçš„ç‰¹å¾
        """
        if self.cmvn is None:
            return inputs
        
        frame, dim = inputs.shape
        means = np.tile(self.cmvn[0:1, :dim], (frame, 1))
        vars = np.tile(self.cmvn[1:2, :dim], (frame, 1))
        inputs = (inputs + means) * vars
        return inputs.astype(np.float32)
    
    def extract_features(
        self, 
        audio: np.ndarray,
        output_format: Literal["numpy", "pytorch", "mlx"] = "numpy"
    ) -> any:
        """
        å®Œæ•´çš„ç‰¹å¾æå–æµç¨‹
        
        Args:
            audio: åŸå§‹éŸ³é¢‘ä¿¡å· (numpy array)
            output_format: è¾“å‡ºæ ¼å¼ ("numpy", "pytorch", "mlx")
            
        Returns:
            å¤„ç†åçš„ç‰¹å¾ï¼Œæ ¼å¼å–å†³äº output_format:
            - "numpy": numpy array [frames, 560]
            - "pytorch": (features, feature_length) å…ƒç»„
            - "mlx": mlx array [1, frames, 560]
        """
        # 1. æå– Fbank ç‰¹å¾
        fbank_features = self.extract_fbank(audio)
        
        # 2. åº”ç”¨ LFR
        lfr_features = self.apply_lfr(fbank_features)
        
        # 3. åº”ç”¨ CMVN
        final_features = self.apply_cmvn(lfr_features)
        
        # 4. æ ¹æ®éœ€è¦çš„æ ¼å¼è¿”å›
        if output_format == "numpy":
            return final_features
        
        elif output_format == "pytorch":
            # PyTorch æ ¼å¼: (features, feature_lengths)
            feat_len = np.array(final_features.shape[0]).astype(np.int32)
            return final_features, feat_len
        
        elif output_format == "mlx":
            # MLX æ ¼å¼: [1, frames, feature_dim]
            import mlx.core as mx
            features_mx = mx.array(final_features, dtype=mx.float32)
            features_mx = mx.expand_dims(features_mx, 0)
            return features_mx
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_format}")
    
    def __call__(self, audio: np.ndarray, output_format: str = "numpy"):
        """å¿«æ·è°ƒç”¨æ–¹æ³•"""
        return self.extract_features(audio, output_format)


def create_frontend_mlx(
    cmvn_file: Optional[str] = "/Users/taylor/.cache/modelscope/hub/models/iic/SenseVoiceSmall/am.mvn",
    **kwargs
) -> UnifiedFrontend:
    """
    åˆ›å»ºç»Ÿä¸€çš„å‰ç«¯å¤„ç†å™¨
    
    Args:
        cmvn_file: CMVNæ–‡ä»¶è·¯å¾„
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        UnifiedFrontend å®ä¾‹
    """
    default_config = {
        'fs': 16000,
        'n_mels': 80,
        'frame_length': 25,
        'frame_shift': 10,
        'lfr_m': 7,
        'lfr_n': 6,
        'window': 'hamming',
        'dither': 1.0,
        'cmvn_file': cmvn_file,
    }
    default_config.update(kwargs)
    return UnifiedFrontend(**default_config)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import librosa
    
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€å‰ç«¯...")
    
    # åŠ è½½æµ‹è¯•éŸ³é¢‘
    audio, sr = librosa.load("examples/ja.mp3", sr=16000, mono=True)
    print(f"éŸ³é¢‘å½¢çŠ¶: {audio.shape}")
    
    # åˆ›å»ºç»Ÿä¸€å‰ç«¯
    frontend = create_unified_frontend()
    
    # æµ‹è¯•ä¸åŒè¾“å‡ºæ ¼å¼
    print("\n1. NumPy æ ¼å¼:")
    features_np = frontend(audio, output_format="numpy")
    print(f"   è¾“å‡ºå½¢çŠ¶: {features_np.shape}")
    print(f"   æ•°æ®ç±»å‹: {features_np.dtype}")
    
    print("\n2. PyTorch æ ¼å¼:")
    features_pt, feat_len = frontend(audio, output_format="pytorch")
    print(f"   ç‰¹å¾å½¢çŠ¶: {features_pt.shape}")
    print(f"   ç‰¹å¾é•¿åº¦: {feat_len}")
    
    print("\n3. MLX æ ¼å¼:")
    features_mlx = frontend(audio, output_format="mlx")
    print(f"   è¾“å‡ºå½¢çŠ¶: {features_mlx.shape}")
    print(f"   æ•°æ®ç±»å‹: {features_mlx.dtype}")
    
    # éªŒè¯ä¸‰ç§æ ¼å¼çš„æ•°å€¼ä¸€è‡´æ€§
    import mlx.core as mx
    features_mlx_np = np.array(features_mlx.squeeze(0))
    
    print("\nâœ… æ•°å€¼ä¸€è‡´æ€§æ£€æŸ¥:")
    # PyTorch è¿”å›çš„æ˜¯å…ƒç»„ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç‰¹å¾
    print(f"   NumPy vs PyTorch ç‰¹å¾æ•°ç»„: {np.array_equal(features_np, features_pt)}")
    print(f"   NumPy vs MLX (allclose):    {np.allclose(features_np, features_mlx_np, rtol=1e-5, atol=1e-6)}")
    
    # è¯¦ç»†æ£€æŸ¥
    diff = np.abs(features_np - features_mlx_np)
    print(f"\n   è¯¦ç»†å·®å¼‚åˆ†æ:")
    print(f"   æœ€å¤§å·®å¼‚: {diff.max():.10f}")
    print(f"   å¹³å‡å·®å¼‚: {diff.mean():.10f}")
    print(f"   å·®å¼‚ä½ç½®: {np.unravel_index(np.argmax(diff), diff.shape)}")
    
    print("\nâœ¨ ç»Ÿä¸€å‰ç«¯æµ‹è¯•å®Œæˆï¼")