#!/usr/bin/env python3
"""
VoiceMLX - SenseVoice MLX æ¨¡å‹å°è£…ç±»
æä¾›ç®€æ´çš„ API æ¥å£è¿›è¡Œè¯­éŸ³è¯†åˆ«
"""

import os
import time
import json
import numpy as np
import librosa
from pathlib import Path
from typing import Optional, Union, Dict, List, Tuple

# MLX ç›¸å…³å¯¼å…¥
import mlx.core as mx

# å¯¼å…¥æ¨¡å‹å’Œå‰ç«¯å¤„ç†
from model_mlx import SenseVoiceMLX
from utils.frontend_mlx import create_frontend_mlx
from utils.postprocess import PunctuationRestorer


class VoiceMLX:
    """SenseVoice MLX æ¨¡å‹å°è£…ç±»
    
    æä¾›ç®€æ´çš„æ¥å£è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œå¤šç§éŸ³é¢‘æ ¼å¼ã€‚
    
    Example:
        >>> voice = VoiceMLX()
        >>> result = voice.transcribe("audio.mp3")
        >>> print(result['text'])
    """
    
    def __init__(
        self,
        model_path: str = "/Users/taylor/Documents/code/SenseVoice/model/model_mlx.safetensors",
        model_dir: str = "/Users/taylor/.cache/modelscope/hub/models/iic/SenseVoiceSmall",
        device: str = "auto",
        verbose: bool = True,
        enable_punctuation: bool = False
    ):
        """åˆå§‹åŒ– VoiceMLX
        
        Args:
            model_path: MLX æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            model_dir: æ¨¡å‹ç›®å½•ï¼ŒåŒ…å« tokenizer å’Œé…ç½®æ–‡ä»¶
            device: è®¾å¤‡ç±»å‹ï¼ˆauto/cpu/gpuï¼‰
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            enable_punctuation: æ˜¯å¦åœ¨åˆå§‹åŒ–æ—¶åŠ è½½å¹¶å¯ç”¨æ ‡ç‚¹æ¢å¤æ¨¡å‹
        """
        self.model_path = model_path
        self.model_dir = model_dir
        self.device = device
        self.verbose = verbose
        self.enable_punctuation = enable_punctuation
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.frontend = None
        self.tokenizer = None
        
        # æ¨¡å‹é…ç½®
        self.model_config = {
            "input_size": 560,  # LFR ç‰¹å¾ç»´åº¦
            "vocab_size": 25055,
            "encoder_conf": {
                "output_size": 512,
                "attention_heads": 4,
                "linear_units": 2048,
                "num_blocks": 50,
                "tp_blocks": 20,
                "dropout_rate": 0.1,
                "positional_dropout_rate": 0.1,
                "attention_dropout_rate": 0.0,
                "normalize_before": True,
                "kernel_size": 11,
                "sanm_shift": 0,
            }
        }
        
        # è¯­è¨€æ˜ å°„
        self.language_map = {
            'zh': 'Chinese',
            'en': 'English',
            'ja': 'Japanese',
            'ko': 'Korean',
            'yue': 'Cantonese',
            'auto': 'Auto-detect'
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        if self.verbose:
            print("ğŸš€ åˆå§‹åŒ– VoiceMLX...")
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
        
        # åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨
        self._init_frontend()
        
        # åŠ è½½ tokenizer
        self._load_tokenizer()
        
        # åˆå§‹åŒ–æ ‡ç‚¹æ¢å¤å™¨ (å¦‚æœç”¨æˆ·é€‰æ‹©å¯ç”¨)
        self.punctuator = None  # å…³é”®ï¼šä¸ºå±æ€§è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„ None å€¼
        
        if self.enable_punctuation:
            # ä»…åœ¨æ ‡å¿—ä¸º True æ—¶ï¼Œæ‰å®ä¾‹åŒ– PunctuationRestorer
            # è¿™å°†è§¦å‘æ ‡ç‚¹æ¨¡å‹çš„åŠ è½½è¿‡ç¨‹
            self.punctuator = PunctuationRestorer(
                device="cpu",  # MLX ç¯å¢ƒä¸‹ä½¿ç”¨ CPU å¤„ç†æ ‡ç‚¹æ¢å¤
                verbose=self.verbose  # ä¿æŒæ—¥å¿—è¾“å‡ºè¡Œä¸ºä¸€è‡´
            )
        
        if self.verbose:
            print("âœ… VoiceMLX åˆå§‹åŒ–å®Œæˆ")
    
    def _load_model(self):
        """åŠ è½½ MLX æ¨¡å‹"""
        if self.verbose:
            print("ğŸ“¦ åŠ è½½ MLX æ¨¡å‹...")
        
        start_time = time.time()
        
        try:
            # åˆå§‹åŒ–æ¨¡å‹æ¶æ„
            self.model = SenseVoiceMLX(
                input_size=self.model_config["input_size"],
                vocab_size=self.model_config["vocab_size"],
                encoder_conf=self.model_config["encoder_conf"]
            )
            
            # åŠ è½½æƒé‡
            if os.path.exists(self.model_path):
                weights = mx.load(self.model_path)
                self.model.load_weights(weights)
                
                if self.verbose:
                    load_time = time.time() - start_time
                    print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _init_frontend(self):
        """åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨"""
        if self.verbose:
            print("ğŸ“ åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨...")
        
        cmvn_file = os.path.join(self.model_dir, "am.mvn")
        self.frontend = create_frontend_mlx(
            cmvn_file=cmvn_file if os.path.exists(cmvn_file) else None
        )
        
        if self.verbose:
            print("   âœ… å‰ç«¯å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def _load_tokenizer(self):
        """åŠ è½½ tokenizer"""
        if self.verbose:
            print("ğŸ“– åŠ è½½ Tokenizer...")
        
        try:
            # å°è¯•åŠ è½½ sentencepiece tokenizer
            from funasr.tokenizer.sentencepiece_tokenizer import SentencepiecesTokenizer
            tokenizer_conf = {
                "sentencepiece_model": os.path.join(self.model_dir, "chn_jpn_yue_eng_ko_spectok.bpe.model")
            }
            self.tokenizer = SentencepiecesTokenizer(**tokenizer_conf)
            
            if self.verbose:
                print("   âœ… SentencePiece Tokenizer åŠ è½½æˆåŠŸ")
        except:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ tokens.json
            try:
                tokens_file = os.path.join(self.model_dir, "tokens.json")
                with open(tokens_file, 'r', encoding='utf-8') as f:
                    tokens = json.load(f)
                
                self.tokenizer = SimpleTokenizer(tokens)
                
                if self.verbose:
                    print("   âœ… Simple Tokenizer åŠ è½½æˆåŠŸ")
            except:
                if self.verbose:
                    print("   âš ï¸  Tokenizer åŠ è½½å¤±è´¥ï¼Œå°†è¿”å› Token IDs")
                self.tokenizer = None
    
    def transcribe(
        self,
        audio: Union[str, np.ndarray],
        language: str = "auto",
        return_tokens: bool = False,
        keep_special_tokens: bool = False,
        sample_rate: int = 16000,
        enable_punctuation: Optional[bool] = None
    ) -> Dict:
        """è½¬å½•éŸ³é¢‘
        
        Args:
            audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–éŸ³é¢‘æ•°ç»„
            language: è¯­è¨€è®¾ç½® (zh/en/ja/ko/yue/auto)
            return_tokens: æ˜¯å¦è¿”å› token IDs
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            sample_rate: é‡‡æ ·ç‡
            enable_punctuation: æ§åˆ¶æ­¤æ¬¡è°ƒç”¨çš„æ ‡ç‚¹æ¢å¤è¡Œä¸ºã€‚
                - True: å¼ºåˆ¶å¯ç”¨æ ‡ç‚¹æ¢å¤ã€‚
                - False: å¼ºåˆ¶ç¦ç”¨æ ‡ç‚¹æ¢å¤ã€‚
                - None (é»˜è®¤): ç»§æ‰¿åˆå§‹åŒ–æ—¶è®¾ç½®çš„ self.enable_punctuation çŠ¶æ€ã€‚
            
        Returns:
            åŒ…å«è¯†åˆ«ç»“æœçš„å­—å…¸ï¼š
            {
                'text': è¯†åˆ«æ–‡æœ¬,
                'language': æ£€æµ‹åˆ°çš„è¯­è¨€,
                'tokens': token IDs (å¦‚æœ return_tokens=True),
                'time': æ¨ç†æ—¶é—´,
                'confidence': ç½®ä¿¡åº¦ (é¢„ç•™)
            }
        """
        # åŠ è½½éŸ³é¢‘
        if isinstance(audio, str):
            if not os.path.exists(audio):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio}")
            waveform, sr = librosa.load(audio, sr=sample_rate, mono=True)
        else:
            waveform = audio
            if len(waveform.shape) > 1:
                waveform = waveform.mean(axis=0)  # è½¬æ¢ä¸ºå•å£°é“
        
        # æå–ç‰¹å¾
        features = self._extract_features(waveform)
        
        # æ‰§è¡Œæ¨ç†
        start_time = time.time()
        text, tokens = self._inference(features, language, keep_special_tokens)
        inference_time = time.time() - start_time
        
        # å†³å®šæ˜¯å¦åº”ç”¨æ ‡ç‚¹æ¢å¤ (ä¼˜å…ˆçº§: æ–¹æ³• > å®ä¾‹)
        use_punctuation = self.enable_punctuation
        if enable_punctuation is not None:
            use_punctuation = enable_punctuation
        
        # å¦‚æœå†³ç­–ä¸º Trueï¼Œå¹¶ä¸”æ ‡ç‚¹æ¢å¤å™¨å·²æˆåŠŸåŠ è½½ï¼Œåˆ™æ‰§è¡Œåå¤„ç†
        if use_punctuation and self.punctuator:
            # æ ¸å¿ƒï¼šç”¨å¸¦æ ‡ç‚¹çš„æ–‡æœ¬è¦†ç›–åŸå§‹æ–‡æœ¬
            text = self.punctuator.restore(text)
        
        # æ„å»ºè¿”å›ç»“æœ
        result = {
            'text': text,
            'language': self._detect_language(text),
            'time': inference_time
        }
        
        if return_tokens:
            result['tokens'] = tokens
        
        return result
    
    def transcribe_batch(
        self,
        audio_files: List[str],
        language: str = "auto",
        **kwargs
    ) -> List[Dict]:
        """æ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            language: è¯­è¨€è®¾ç½®
            **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™ transcribe
            
        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        results = []
        
        for audio_file in audio_files:
            try:
                result = self.transcribe(audio_file, language, **kwargs)
                result['file'] = os.path.basename(audio_file)
                results.append(result)
            except Exception as e:
                results.append({
                    'file': os.path.basename(audio_file),
                    'text': f"[é”™è¯¯: {str(e)}]",
                    'error': str(e)
                })
        
        return results
    
    def _extract_features(self, waveform: np.ndarray) -> mx.array:
        """æå–éŸ³é¢‘ç‰¹å¾
        
        Args:
            waveform: éŸ³é¢‘æ³¢å½¢æ•°ç»„
            
        Returns:
            MLX æ ¼å¼çš„ç‰¹å¾æ•°ç»„
        """
        # ä½¿ç”¨å‰ç«¯å¤„ç†å™¨æå–ç‰¹å¾
        features = self.frontend(waveform, output_format="mlx")
        return features
    
    def _inference(
        self,
        features: mx.array,
        language: str = "auto",
        keep_special_tokens: bool = False
    ) -> Tuple[str, List[int]]:
        """æ‰§è¡Œæ¨¡å‹æ¨ç†
        
        Args:
            features: éŸ³é¢‘ç‰¹å¾
            language: è¯­è¨€è®¾ç½®
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            
        Returns:
            (è¯†åˆ«æ–‡æœ¬, token IDs)
        """
        # å‡†å¤‡è¾“å…¥
        speech_lengths = mx.array([features.shape[1]], dtype=mx.int32)
        
        # æ‰§è¡Œæ¨ç†
        outputs = self.model(features, speech_lengths)
        ctc_logits = outputs['ctc_logits']
        
        # CTC è§£ç 
        token_ids = mx.argmax(ctc_logits[0], axis=-1)
        
        # å»é™¤é‡å¤å’Œç©ºç™½æ ‡è®°
        token_ids_np = np.array(token_ids)
        decoded_tokens = []
        prev_token = -1
        
        for token in token_ids_np:
            if token != prev_token and token != 0:  # 0 æ˜¯ blank token
                decoded_tokens.append(int(token))
            prev_token = token
        
        # è§£ç ä¸ºæ–‡æœ¬
        if self.tokenizer and len(decoded_tokens) > 0:
            try:
                text = self.tokenizer.decode(decoded_tokens, keep_special_tokens=keep_special_tokens)
            except:
                text = self._tokens_to_string(decoded_tokens)
        else:
            text = self._tokens_to_string(decoded_tokens)
        
        return text, decoded_tokens
    
    def _tokens_to_string(self, tokens: List[int]) -> str:
        """å°† token IDs è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º"""
        if len(tokens) > 20:
            return f"[Tokens: {tokens[:20]}...]"
        else:
            return f"[Tokens: {tokens}]"
    
    def _detect_language(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æ£€æµ‹è¯­è¨€
        
        Args:
            text: è¯†åˆ«æ–‡æœ¬
            
        Returns:
            æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç 
        """
        # æ£€æŸ¥ç‰¹æ®Šæ ‡è®°
        language_tags = {
            '<|zh|>': 'zh',
            '<|en|>': 'en',
            '<|ja|>': 'ja',
            '<|ko|>': 'ko',
            '<|yue|>': 'yue'
        }
        
        for tag, lang in language_tags.items():
            if tag in text:
                return lang
        
        return 'auto'
    
    def benchmark(self, audio_file: str, iterations: int = 10) -> Dict:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            audio_file: æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
            iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
            
        Returns:
            æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        """
        times = []
        
        for i in range(iterations):
            result = self.transcribe(audio_file, keep_special_tokens=False)
            times.append(result['time'])
        
        return {
            'mean_time': np.mean(times),
            'std_time': np.std(times),
            'min_time': np.min(times),
            'max_time': np.max(times),
            'iterations': iterations
        }


class SimpleTokenizer:
    """ç®€å•çš„ Tokenizer å®ç°"""
    
    def __init__(self, tokens: List[str]):
        """åˆå§‹åŒ–
        
        Args:
            tokens: token åˆ—è¡¨
        """
        self.tokens = tokens
        self.id2token = {i: token for i, token in enumerate(tokens)}
    
    def decode(self, token_ids: List[int], keep_special_tokens: bool = False) -> str:
        """å°† token IDs è§£ç ä¸ºæ–‡æœ¬
        
        Args:
            token_ids: Token ID åˆ—è¡¨
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            
        Returns:
            è§£ç åçš„æ–‡æœ¬
        """
        text_tokens = []
        
        for tid in token_ids:
            if tid in self.id2token:
                token = self.id2token[tid]
                # æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦è·³è¿‡ç‰¹æ®Šæ ‡è®°
                if keep_special_tokens or not (token.startswith('<') and token.endswith('>')):
                    text_tokens.append(token)
        
        # åˆå¹¶æ–‡æœ¬
        text = ''.join(text_tokens)
        # æ¸…ç†æ–‡æœ¬
        text = text.replace('â–', ' ')  # æ›¿æ¢ç©ºæ ¼æ ‡è®°
        text = text.strip()
        
        return text


def main():
    """
    ä¸€ä¸ªç”¨äºéªŒè¯æ ‡ç‚¹æ¢å¤åŠŸèƒ½çš„é›†æˆæµ‹è¯•æ¡©ã€‚
    è¯¥å‡½æ•°å°†æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰å…³é”®æµ‹è¯•åœºæ™¯ã€‚
    """
    print("=" * 80)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ VoiceMLX é›†æˆæµ‹è¯•...")
    print("=" * 80)

    # å‡†å¤‡æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    examples_dir = "/Users/taylor/Documents/code/SenseVoice/examples"
    audio_file = os.path.join(examples_dir, "zh.mp3")  # ä½¿ç”¨ä¸­æ–‡éŸ³é¢‘æµ‹è¯•æ ‡ç‚¹æ¢å¤

    if not os.path.exists(audio_file):
        print(f"âŒ æµ‹è¯•å¤±è´¥: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨äº {audio_file}")
        return

    print(f"ğŸµ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {os.path.basename(audio_file)}\n")

    # --- æµ‹è¯•åœºæ™¯ A: é»˜è®¤è¡Œä¸º (å‘åå…¼å®¹æ€§) ---
    print("--- [æµ‹è¯•åœºæ™¯ A]: é»˜è®¤è¡Œä¸º (æ ‡ç‚¹ç¦ç”¨) ---")
    try:
        # ä½¿ç”¨ verbose=False ä¿æŒè¾“å‡ºå¹²å‡€
        voice_default = VoiceMLX(verbose=False)
        result_A = voice_default.transcribe(audio_file, keep_special_tokens=False)
        print(f"  [é¢„æœŸ (æ— æ ‡ç‚¹)]: {result_A['text']}\n")
    except Exception as e:
        print(f"  âŒ æµ‹è¯•åœºæ™¯ A å¤±è´¥: {e}\n")


    # --- æµ‹è¯•åœºæ™¯ B: åˆå§‹åŒ–æ—¶å¯ç”¨æ ‡ç‚¹ ---
    print("--- [æµ‹è¯•åœºæ™¯ B]: åˆå§‹åŒ–æ—¶å¯ç”¨æ ‡ç‚¹ ---")
    try:
        voice_punc_on = VoiceMLX(enable_punctuation=True, verbose=False)
        result_B = voice_punc_on.transcribe(audio_file, keep_special_tokens=False)
        print(f"  [é¢„æœŸ (æœ‰æ ‡ç‚¹)]: {result_B['text']}\n")
    except Exception as e:
        print(f"  âŒ æµ‹è¯•åœºæ™¯ B å¤±è´¥: {e}\n")


    # --- æµ‹è¯•åœºæ™¯ C: åŠ¨æ€è¦†ç›–æ–¹æ³•è°ƒç”¨ ---
    print("--- [æµ‹è¯•åœºæ™¯ C]: åŠ¨æ€è¦†ç›–æ–¹æ³•è°ƒç”¨ ---")
    # C.1: åœ¨é»˜è®¤å®ä¾‹ä¸Šï¼Œå•æ¬¡è°ƒç”¨æ—¶å¼ºåˆ¶å¯ç”¨æ ‡ç‚¹
    print("  --- [C.1]: åœ¨é»˜è®¤å®ä¾‹ä¸Šå•æ¬¡å¯ç”¨ ---")
    try:
        result_C1 = voice_default.transcribe(
            audio_file,
            enable_punctuation=True,
            keep_special_tokens=False
        )
        print(f"    [é¢„æœŸ (æœ‰æ ‡ç‚¹)]: {result_C1['text']}\n")
    except Exception as e:
        print(f"    âŒ æµ‹è¯•åœºæ™¯ C.1 å¤±è´¥: {e}\n")

    # C.2: åœ¨æ ‡ç‚¹å®ä¾‹ä¸Šï¼Œå•æ¬¡è°ƒç”¨æ—¶å¼ºåˆ¶ç¦ç”¨æ ‡ç‚¹
    print("  --- [C.2]: åœ¨æ ‡ç‚¹å®ä¾‹ä¸Šå•æ¬¡ç¦ç”¨ ---")
    try:
        result_C2 = voice_punc_on.transcribe(
            audio_file,
            enable_punctuation=False,
            keep_special_tokens=False
        )
        print(f"    [é¢„æœŸ (æ— æ ‡ç‚¹)]: {result_C2['text']}\n")
    except Exception as e:
        print(f"    âŒ æµ‹è¯•åœºæ™¯ C.2 å¤±è´¥: {e}\n")

    print("=" * 80)
    print("âœ… æµ‹è¯•æ‰§è¡Œå®Œæ¯•ã€‚è¯·æ£€æŸ¥ä»¥ä¸Šè¾“å‡ºæ˜¯å¦ç¬¦åˆé¢„æœŸã€‚")
    print("=" * 80)


if __name__ == "__main__":
    main()