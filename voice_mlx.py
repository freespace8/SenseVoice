#!/usr/bin/env python3
"""
VoiceMLX - SenseVoice MLX æ¨¡å‹å°è£…ç±»
æä¾›ç®€æ´çš„ API æ¥å£è¿›è¡Œè¯­éŸ³è¯†åˆ«
"""

import os
import time
import json
import numpy as np
import librosa
from pathlib import Path
from typing import Optional, Union, Dict, List, Tuple

# MLX ç›¸å…³å¯¼å…¥
import mlx.core as mx

# å¯¼å…¥æ¨¡å‹å’Œå‰ç«¯å¤„ç†
from model_mlx import SenseVoiceMLX
from utils.frontend_mlx import create_frontend_mlx


class VoiceMLX:
    """SenseVoice MLX æ¨¡å‹å°è£…ç±»
    
    æä¾›ç®€æ´çš„æ¥å£è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒå¤šè¯­è¨€å’Œå¤šç§éŸ³é¢‘æ ¼å¼ã€‚
    
    Example:
        >>> voice = VoiceMLX()
        >>> result = voice.transcribe("audio.mp3")
        >>> print(result['text'])
    """
    
    def __init__(
        self,
        model_path: str = "/Users/taylor/Documents/code/SenseVoice/model/model_mlx.safetensors",
        model_dir: str = "/Users/taylor/.cache/modelscope/hub/models/iic/SenseVoiceSmall",
        device: str = "auto",
        verbose: bool = True
    ):
        """åˆå§‹åŒ– VoiceMLX
        
        Args:
            model_path: MLX æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            model_dir: æ¨¡å‹ç›®å½•ï¼ŒåŒ…å« tokenizer å’Œé…ç½®æ–‡ä»¶
            device: è®¾å¤‡ç±»å‹ï¼ˆauto/cpu/gpuï¼‰
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        """
        self.model_path = model_path
        self.model_dir = model_dir
        self.device = device
        self.verbose = verbose
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.frontend = None
        self.tokenizer = None
        
        # æ¨¡å‹é…ç½®
        self.model_config = {
            "input_size": 560,  # LFR ç‰¹å¾ç»´åº¦
            "vocab_size": 25055,
            "encoder_conf": {
                "output_size": 512,
                "attention_heads": 4,
                "linear_units": 2048,
                "num_blocks": 50,
                "tp_blocks": 20,
                "dropout_rate": 0.1,
                "positional_dropout_rate": 0.1,
                "attention_dropout_rate": 0.0,
                "normalize_before": True,
                "kernel_size": 11,
                "sanm_shift": 0,
            }
        }
        
        # è¯­è¨€æ˜ å°„
        self.language_map = {
            'zh': 'Chinese',
            'en': 'English',
            'ja': 'Japanese',
            'ko': 'Korean',
            'yue': 'Cantonese',
            'auto': 'Auto-detect'
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        if self.verbose:
            print("ğŸš€ åˆå§‹åŒ– VoiceMLX...")
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
        
        # åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨
        self._init_frontend()
        
        # åŠ è½½ tokenizer
        self._load_tokenizer()
        
        if self.verbose:
            print("âœ… VoiceMLX åˆå§‹åŒ–å®Œæˆ")
    
    def _load_model(self):
        """åŠ è½½ MLX æ¨¡å‹"""
        if self.verbose:
            print("ğŸ“¦ åŠ è½½ MLX æ¨¡å‹...")
        
        start_time = time.time()
        
        try:
            # åˆå§‹åŒ–æ¨¡å‹æ¶æ„
            self.model = SenseVoiceMLX(
                input_size=self.model_config["input_size"],
                vocab_size=self.model_config["vocab_size"],
                encoder_conf=self.model_config["encoder_conf"]
            )
            
            # åŠ è½½æƒé‡
            if os.path.exists(self.model_path):
                weights = mx.load(self.model_path)
                self.model.load_weights(weights)
                
                if self.verbose:
                    load_time = time.time() - start_time
                    print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
            else:
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _init_frontend(self):
        """åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨"""
        if self.verbose:
            print("ğŸ“ åˆå§‹åŒ–å‰ç«¯å¤„ç†å™¨...")
        
        cmvn_file = os.path.join(self.model_dir, "am.mvn")
        self.frontend = create_frontend_mlx(
            cmvn_file=cmvn_file if os.path.exists(cmvn_file) else None
        )
        
        if self.verbose:
            print("   âœ… å‰ç«¯å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    def _load_tokenizer(self):
        """åŠ è½½ tokenizer"""
        if self.verbose:
            print("ğŸ“– åŠ è½½ Tokenizer...")
        
        try:
            # å°è¯•åŠ è½½ sentencepiece tokenizer
            from funasr.tokenizer.sentencepiece_tokenizer import SentencepiecesTokenizer
            tokenizer_conf = {
                "sentencepiece_model": os.path.join(self.model_dir, "chn_jpn_yue_eng_ko_spectok.bpe.model")
            }
            self.tokenizer = SentencepiecesTokenizer(**tokenizer_conf)
            
            if self.verbose:
                print("   âœ… SentencePiece Tokenizer åŠ è½½æˆåŠŸ")
        except:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ tokens.json
            try:
                tokens_file = os.path.join(self.model_dir, "tokens.json")
                with open(tokens_file, 'r', encoding='utf-8') as f:
                    tokens = json.load(f)
                
                self.tokenizer = SimpleTokenizer(tokens)
                
                if self.verbose:
                    print("   âœ… Simple Tokenizer åŠ è½½æˆåŠŸ")
            except:
                if self.verbose:
                    print("   âš ï¸  Tokenizer åŠ è½½å¤±è´¥ï¼Œå°†è¿”å› Token IDs")
                self.tokenizer = None
    
    def transcribe(
        self,
        audio: Union[str, np.ndarray],
        language: str = "auto",
        return_tokens: bool = False,
        keep_special_tokens: bool = False,
        sample_rate: int = 16000
    ) -> Dict:
        """è½¬å½•éŸ³é¢‘
        
        Args:
            audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–éŸ³é¢‘æ•°ç»„
            language: è¯­è¨€è®¾ç½® (zh/en/ja/ko/yue/auto)
            return_tokens: æ˜¯å¦è¿”å› token IDs
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            åŒ…å«è¯†åˆ«ç»“æœçš„å­—å…¸ï¼š
            {
                'text': è¯†åˆ«æ–‡æœ¬,
                'language': æ£€æµ‹åˆ°çš„è¯­è¨€,
                'tokens': token IDs (å¦‚æœ return_tokens=True),
                'time': æ¨ç†æ—¶é—´,
                'confidence': ç½®ä¿¡åº¦ (é¢„ç•™)
            }
        """
        # åŠ è½½éŸ³é¢‘
        if isinstance(audio, str):
            if not os.path.exists(audio):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio}")
            waveform, sr = librosa.load(audio, sr=sample_rate, mono=True)
        else:
            waveform = audio
            if len(waveform.shape) > 1:
                waveform = waveform.mean(axis=0)  # è½¬æ¢ä¸ºå•å£°é“
        
        # æå–ç‰¹å¾
        features = self._extract_features(waveform)
        
        # æ‰§è¡Œæ¨ç†
        start_time = time.time()
        text, tokens = self._inference(features, language, keep_special_tokens)
        inference_time = time.time() - start_time
        
        # æ„å»ºè¿”å›ç»“æœ
        result = {
            'text': text,
            'language': self._detect_language(text),
            'time': inference_time
        }
        
        if return_tokens:
            result['tokens'] = tokens
        
        return result
    
    def transcribe_batch(
        self,
        audio_files: List[str],
        language: str = "auto",
        **kwargs
    ) -> List[Dict]:
        """æ‰¹é‡è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            language: è¯­è¨€è®¾ç½®
            **kwargs: å…¶ä»–å‚æ•°ä¼ é€’ç»™ transcribe
            
        Returns:
            è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        results = []
        
        for audio_file in audio_files:
            try:
                result = self.transcribe(audio_file, language, **kwargs)
                result['file'] = os.path.basename(audio_file)
                results.append(result)
            except Exception as e:
                results.append({
                    'file': os.path.basename(audio_file),
                    'text': f"[é”™è¯¯: {str(e)}]",
                    'error': str(e)
                })
        
        return results
    
    def _extract_features(self, waveform: np.ndarray) -> mx.array:
        """æå–éŸ³é¢‘ç‰¹å¾
        
        Args:
            waveform: éŸ³é¢‘æ³¢å½¢æ•°ç»„
            
        Returns:
            MLX æ ¼å¼çš„ç‰¹å¾æ•°ç»„
        """
        # ä½¿ç”¨å‰ç«¯å¤„ç†å™¨æå–ç‰¹å¾
        features = self.frontend(waveform, output_format="mlx")
        return features
    
    def _inference(
        self,
        features: mx.array,
        language: str = "auto",
        keep_special_tokens: bool = False
    ) -> Tuple[str, List[int]]:
        """æ‰§è¡Œæ¨¡å‹æ¨ç†
        
        Args:
            features: éŸ³é¢‘ç‰¹å¾
            language: è¯­è¨€è®¾ç½®
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            
        Returns:
            (è¯†åˆ«æ–‡æœ¬, token IDs)
        """
        # å‡†å¤‡è¾“å…¥
        speech_lengths = mx.array([features.shape[1]], dtype=mx.int32)
        
        # æ‰§è¡Œæ¨ç†
        outputs = self.model(features, speech_lengths)
        ctc_logits = outputs['ctc_logits']
        
        # CTC è§£ç 
        token_ids = mx.argmax(ctc_logits[0], axis=-1)
        
        # å»é™¤é‡å¤å’Œç©ºç™½æ ‡è®°
        token_ids_np = np.array(token_ids)
        decoded_tokens = []
        prev_token = -1
        
        for token in token_ids_np:
            if token != prev_token and token != 0:  # 0 æ˜¯ blank token
                decoded_tokens.append(int(token))
            prev_token = token
        
        # è§£ç ä¸ºæ–‡æœ¬
        if self.tokenizer and len(decoded_tokens) > 0:
            try:
                text = self.tokenizer.decode(decoded_tokens, keep_special_tokens=keep_special_tokens)
            except:
                text = self._tokens_to_string(decoded_tokens)
        else:
            text = self._tokens_to_string(decoded_tokens)
        
        return text, decoded_tokens
    
    def _tokens_to_string(self, tokens: List[int]) -> str:
        """å°† token IDs è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º"""
        if len(tokens) > 20:
            return f"[Tokens: {tokens[:20]}...]"
        else:
            return f"[Tokens: {tokens}]"
    
    def _detect_language(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æ£€æµ‹è¯­è¨€
        
        Args:
            text: è¯†åˆ«æ–‡æœ¬
            
        Returns:
            æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç 
        """
        # æ£€æŸ¥ç‰¹æ®Šæ ‡è®°
        language_tags = {
            '<|zh|>': 'zh',
            '<|en|>': 'en',
            '<|ja|>': 'ja',
            '<|ko|>': 'ko',
            '<|yue|>': 'yue'
        }
        
        for tag, lang in language_tags.items():
            if tag in text:
                return lang
        
        return 'auto'
    
    def benchmark(self, audio_file: str, iterations: int = 10) -> Dict:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        Args:
            audio_file: æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
            iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
            
        Returns:
            æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        """
        times = []
        
        for i in range(iterations):
            result = self.transcribe(audio_file, keep_special_tokens=False)
            times.append(result['time'])
        
        return {
            'mean_time': np.mean(times),
            'std_time': np.std(times),
            'min_time': np.min(times),
            'max_time': np.max(times),
            'iterations': iterations
        }


class SimpleTokenizer:
    """ç®€å•çš„ Tokenizer å®ç°"""
    
    def __init__(self, tokens: List[str]):
        """åˆå§‹åŒ–
        
        Args:
            tokens: token åˆ—è¡¨
        """
        self.tokens = tokens
        self.id2token = {i: token for i, token in enumerate(tokens)}
    
    def decode(self, token_ids: List[int], keep_special_tokens: bool = False) -> str:
        """å°† token IDs è§£ç ä¸ºæ–‡æœ¬
        
        Args:
            token_ids: Token ID åˆ—è¡¨
            keep_special_tokens: æ˜¯å¦ä¿ç•™ç‰¹æ®Šæ ‡è®°
            
        Returns:
            è§£ç åçš„æ–‡æœ¬
        """
        text_tokens = []
        
        for tid in token_ids:
            if tid in self.id2token:
                token = self.id2token[tid]
                # æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦è·³è¿‡ç‰¹æ®Šæ ‡è®°
                if keep_special_tokens or not (token.startswith('<') and token.endswith('>')):
                    text_tokens.append(token)
        
        # åˆå¹¶æ–‡æœ¬
        text = ''.join(text_tokens)
        # æ¸…ç†æ–‡æœ¬
        text = text.replace('â–', ' ')  # æ›¿æ¢ç©ºæ ¼æ ‡è®°
        text = text.strip()
        
        return text


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»º VoiceMLX å®ä¾‹
    voice = VoiceMLX(verbose=True)
    
    # ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶
    examples_dir = "/Users/taylor/Documents/code/SenseVoice/examples"
    
    if os.path.exists(examples_dir):
        audio_files = [
            os.path.join(examples_dir, f)
            for f in os.listdir(examples_dir)
            if f.endswith('.mp3')
        ]
        
        if audio_files:
            print("\n" + "=" * 60)
            print("ğŸ“ è½¬å½•ç¤ºä¾‹")
            print("=" * 60)
            
            for audio_file in audio_files[:2]:  # åªæµ‹è¯•å‰ä¸¤ä¸ªæ–‡ä»¶
                print(f"\nğŸµ éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}")
                
                # è½¬å½•
                result = voice.transcribe(
                    audio_file,
                    language="auto",
                    keep_special_tokens=True
                )
                
                print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result['text']}")
                print(f"â±ï¸  æ¨ç†æ—¶é—´: {result['time']:.3f}ç§’")
                print(f"ğŸŒ æ£€æµ‹è¯­è¨€: {result['language']}")
            
            # æ€§èƒ½åŸºå‡†æµ‹è¯•
            if audio_files:
                print("\n" + "=" * 60)
                print("âš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
                print("=" * 60)
                
                benchmark = voice.benchmark(audio_files[0], iterations=5)
                print(f"å¹³å‡æ—¶é—´: {benchmark['mean_time']:.3f}ç§’")
                print(f"æ ‡å‡†å·®: {benchmark['std_time']:.3f}ç§’")
                print(f"æœ€å¿«: {benchmark['min_time']:.3f}ç§’")
                print(f"æœ€æ…¢: {benchmark['max_time']:.3f}ç§’")


if __name__ == "__main__":
    main()